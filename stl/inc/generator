// generator standard header

// Copyright (c) Microsoft Corporation.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception

#pragma once
#ifndef _GENERATOR_
#define _GENERATOR_
#include <yvals_core.h>
#if _STL_COMPILER_PREPROCESSOR

#if !_HAS_CXX23 || !defined(__cpp_lib_byte) || !defined(__cpp_impl_coroutine)
#pragma message("The contents of <generator> are available only in c++latest mode with coroutine and std::byte support")
#else // ^^^ no coroutine support / coroutines vvv

#include <coroutine>
#include <xmemory>

#pragma pack(push, _CRT_PACKING)
#pragma warning(push, _STL_WARNING_LEVEL)
#pragma warning(disable : _STL_DISABLED_WARNINGS)
_STL_DISABLE_CLANG_WARNINGS
#pragma push_macro("new")
#undef new

_STD_BEGIN

struct alignas(__STDCPP_DEFAULT_NEW_ALIGNMENT__) _Aligned_block {};

template <class _Allocator = void>
struct _Promise_allocator {
    // clang-format off
    static void* operator new(size_t _Size) requires (is_void_v<_Allocator> || default_initializable<_Allocator>) {
        // clang-format on
        if constexpr (is_void_v<_Allocator>) {
            // type-erase new/delete
            void* const _Ptr                      = ::operator new[](_Size + sizeof(void (*)(void*)));
            void (*const _Dealloc)(void*, size_t) = [](void* _Block, size_t _Size) {
                ::operator delete[](_Block, _Size + sizeof(void (*)(void*)));
            };
            _CSTD memcpy(static_cast<char*>(_Ptr) + _Size, &_Dealloc, sizeof(_Dealloc));
            return _Ptr;
        } else {
            // statically specified
            using _Alloc = _Rebind_alloc_t<_Allocator, _Aligned_block>;
            _Alloc _Al{};

            if constexpr (allocator_traits<_Alloc>::is_always_equal::value) {
                // do not store stateless allocator
                const size_t _Count = (_Size + sizeof(_Aligned_block) - 1) / sizeof(_Aligned_block);
                return _Al.allocate(_Count);
            } else {
                // store stateful allocator
                const size_t _Count = (_Size + sizeof(_Alloc) + alignof(_Alloc) - 1 + sizeof(_Aligned_block) - 1)
                                    / sizeof(_Aligned_block);
                void* const _Ptr = _Al.allocate(_Count);
                const auto _Al_address =
                    (reinterpret_cast<uintptr_t>(_Ptr) + _Size + alignof(_Alloc) - 1) & ~(alignof(_Alloc) - 1);
                ::new (reinterpret_cast<void*>(_Al_address)) _Alloc{_STD move(_Al)};
                return _Ptr;
            }
        }
    }

    template <class _Alloc2, class... _Args>
        requires is_void_v<_Allocator> || convertible_to<const _Alloc2&, _Allocator>
    static void* operator new(size_t _Size, allocator_arg_t, const _Alloc2& _Al2, _Args&...) {
        if constexpr (is_void_v<_Allocator>) {
            // type-erase the provided allocator
            using _Alloc = _Rebind_alloc_t<_Alloc2, _Aligned_block>;
            _Alloc _Al{_Al2};

            if constexpr (default_initializable<_Alloc> && allocator_traits<_Alloc>::is_always_equal::value) {
                // don't store stateless allocator
                void (*const _Dealloc)(void*, size_t) = [](void* _Block, size_t _Size) {
                    _Alloc _Al{};
                    _Size += sizeof(void (*)(void*, size_t));
                    const size_t _Count = (_Size + sizeof(_Aligned_block) - 1) / sizeof(_Aligned_block);
                    _Al.deallocate(static_cast<_Aligned_block*>(_Block), _Count);
                };

                const size_t _Count =
                    (_Size + sizeof(void (*)(void*, size_t)) + sizeof(_Aligned_block) - 1) / sizeof(_Aligned_block);
                void* const _Ptr = _Al.allocate(_Count);
                _CSTD memcpy(static_cast<char*>(_Ptr) + _Size, &_Dealloc, sizeof(_Dealloc));
                return _Ptr;
            } else {
                // store stateful allocator
                constexpr size_t _Align = (_STD max) (alignof(_Alloc), sizeof(_Aligned_block));

                void (*const _Dealloc)(void*, size_t) = [](void* _Block, size_t _Size) {
                    _Size += sizeof(void (*)(void*, size_t));
                    const auto _Al_address =
                        (reinterpret_cast<uintptr_t>(_Block) + _Size + alignof(_Alloc) - 1) & ~(alignof(_Alloc) - 1);
                    auto& _Stored_al = *reinterpret_cast<const _Alloc*>(_Al_address);
                    _Alloc _Al{_STD move(_Stored_al)};
                    _Stored_al.~_Alloc();

                    const size_t _Count = (_Size + sizeof(_Al) + _Align - 1) / sizeof(_Aligned_block);
                    _Al.deallocate(static_cast<_Aligned_block*>(_Block), _Count);
                };

                const size_t _Count =
                    (_Size + sizeof(void (*)(void*, size_t)) + sizeof(_Al) + _Align - 1) / sizeof(_Aligned_block);
                void* const _Ptr = _Al.allocate(_Count);
                _CSTD memcpy(static_cast<char*>(_Ptr) + _Size, &_Dealloc, sizeof(_Dealloc));
                _Size += sizeof(void (*)(void*, size_t));
                const auto _Al_address =
                    (reinterpret_cast<uintptr_t>(_Ptr) + _Size + alignof(_Alloc) - 1) & ~(alignof(_Alloc) - 1);
                ::new (reinterpret_cast<void*>(_Al_address)) _Alloc{_STD move(_Al)};
                return _Ptr;
            }
        } else {
            // statically specified allocator type
            using _Alloc = _Rebind_alloc_t<_Allocator, _Aligned_block>;
            _Alloc _Al{static_cast<_Allocator>(_Al2)};

            if constexpr (default_initializable<_Allocator> && allocator_traits<_Alloc>::is_always_equal::value) {
                // do not store stateless allocator
                const size_t _Count = (_Size + sizeof(_Aligned_block) - 1) / sizeof(_Aligned_block);
                return _Al.allocate(_Count);
            } else {
                // store stateful allocator
                constexpr size_t _Align = (_STD max) (alignof(_Alloc), sizeof(_Aligned_block));
                const size_t _Count     = (_Size + sizeof(_Alloc) + _Align - 1) / sizeof(_Aligned_block);

                void* const _Ptr = _Al.allocate(_Count);
                const auto _Al_address =
                    (reinterpret_cast<uintptr_t>(_Ptr) + _Size + alignof(_Alloc) - 1) & ~(alignof(_Alloc) - 1);
                ::new (reinterpret_cast<void*>(_Al_address)) _Alloc{_STD move(_Al)};
                return _Ptr;
            }
        }
    }

    template <class _This, class _Alloc2, class... _Types>
        requires is_void_v<_Allocator> || convertible_to<const _Alloc2&, _Allocator>
    static void* operator new(size_t _Size, _This&, allocator_arg_t, const _Alloc2& _Al, _Types&... _Args) {
        return operator new(_Size, allocator_arg, _Al, _Args...);
    }

    static void operator delete(void* _Ptr, size_t _Size) noexcept {
        if constexpr (is_void_v<_Allocator>) {
            // use erased deallocator
            void (*_Dealloc)(void*, size_t);
            _CSTD memcpy(&_Dealloc, static_cast<const char*>(_Ptr) + _Size, sizeof(_Dealloc));
            _Dealloc(_Ptr, _Size);
        } else {
            using _Alloc = _Rebind_alloc_t<_Allocator, _Aligned_block>;
            if constexpr (default_initializable<_Alloc> && allocator_traits<_Alloc>::is_always_equal::value) {
                // make stateless allocator
                _Alloc _Al{};
                const size_t _Count = (_Size + sizeof(_Aligned_block) - 1) / sizeof(_Aligned_block);
                _Al.deallocate(static_cast<_Aligned_block*>(_Ptr), _Count);
            } else {
                // retrieve stateful allocator
                const auto _Al_address =
                    (reinterpret_cast<uintptr_t>(_Ptr) + _Size + alignof(_Alloc) - 1) & ~(alignof(_Alloc) - 1);
                auto& _Stored_al = *reinterpret_cast<_Alloc*>(_Al_address);
                _Alloc _Al{_STD move(_Stored_al)};
                _Stored_al.~_Alloc();

                constexpr size_t _Align = (_STD max) (alignof(_Alloc), sizeof(_Aligned_block));
                const size_t _Count     = (_Size + sizeof(_Alloc) + _Align - 1) / sizeof(_Aligned_block);
                _Al.deallocate(static_cast<_Aligned_block*>(_Ptr), _Count);
            }
        }
    }
};

template <class _Ty, class _Ref = const _Ty&, class _Allocator = void>
class generator;

template <class _Ref>
struct _Generator_promise_base {
    add_pointer_t<_Ref> _Ptr = nullptr;

    suspend_always initial_suspend() noexcept {
        return {};
    }

    suspend_always final_suspend() noexcept {
        return {};
    }

    suspend_always yield_value(_Ref&& _Val) noexcept {
        _Ptr = _STD addressof(_Val);
        return {};
    }

#if 1 // BORKEN
    template <class _Ty, class _Alloc>
    struct _Nested_awaitable {
        generator<_Ty, _Ref, _Alloc> _Gen;
        coroutine_handle<_Generator_promise_base> _Outer;

        bool await_ready() noexcept {
            return false;
        }

        template <derived_from<_Generator_promise_base> _Promise>
        coroutine_handle<_Generator_promise_base> await_suspend(coroutine_handle<_Promise> _Outer_) {
            _Outer = coroutine_handle<_Generator_promise_base>::from_address(_Outer_.address());
            return coroutine_handle<_Generator_promise_base>::from_address(_Gen._Coro.address());
        }

        void await_resume() noexcept {}
    };

    template <class _Ty, class _Alloc>
    auto yield_value(ranges::elements_of<generator<_Ty, _Ref, _Alloc>> _Elem) noexcept {
        return _Nested_awaitable<_Ty, _Alloc>{_Elem.range()};
    }
#endif // BORKEN

    void await_transform() = delete;

    void return_void() noexcept {}

#ifndef _KERNEL_MODE
#ifdef _CPPUNWIND
    [[noreturn]] void unhandled_exception() {
        throw;
    }
#else // ^^^ defined(_CPPUNWIND) / !defined(_CPPUNWIND) vvv
    void unhandled_exception() noexcept {}
#endif // _CPPUNWIND
#endif // _KERNEL_MODE
};

template <class _Ty, class _Ref>
struct _Generator_iterator {
    using difference_type = ptrdiff_t;
    using value_type      = _Ty;

    coroutine_handle<_Generator_promise_base<_Ref>> _Coro;

    _NODISCARD _Ref&& operator*() const noexcept {
#ifndef _KERNEL_MODE
        _STL_ASSERT(!_Coro.done(), "Can't dereference generator end iterator");
#endif // _KERNEL_MODE
        return static_cast<_Ref&&>(*_Coro.promise()._Ptr);
    }

    _Generator_iterator& operator++() {
#ifndef _KERNEL_MODE
        _STL_ASSERT(!_Coro.done(), "Can't increment generator end iterator");
#endif // _KERNEL_MODE
        _Coro.resume();
        return *this;
    }

    void operator++(int) {
        ++*this;
    }

    _NODISCARD bool operator==(default_sentinel_t) const noexcept {
        return _Coro.done();
    }
};

template <class _Ty, class _Ref, class _Allocator>
class generator {
public:
    struct __declspec(empty_bases) promise_type : _Promise_allocator<_Allocator>, _Generator_promise_base<_Ref> {
        generator get_return_object() noexcept {
            return generator(coroutine_handle<promise_type>::from_promise(*this));
        }
    };
    static_assert(is_standard_layout_v<promise_type>);

    coroutine_handle<promise_type> _Coro = nullptr;

    generator(generator&& _Right) noexcept : _Coro(_STD exchange(_Right._Coro, nullptr)) {}

    ~generator() {
        if (_Coro) {
            _Coro.destroy();
        }
    }

    generator& operator=(generator&& _Right) noexcept {
        _Coro = _STD exchange(_Right._Coro, nullptr);
        return *this;
    }

    _NODISCARD _Generator_iterator<_Ty, _Ref> begin() {
        // Pre: _Coro is suspended at its initial suspend point
#ifndef _KERNEL_MODE
        _STL_ASSERT(_Coro, "Can't call begin on moved-from generator");
#endif // _KERNEL_MODE
        _Coro.resume();
        return _Generator_iterator<_Ty, _Ref>{
            coroutine_handle<_Generator_promise_base<_Ref>>::from_address(_Coro.address())};
    }

    _NODISCARD default_sentinel_t end() const noexcept {
        return default_sentinel;
    }

private:
    explicit generator(coroutine_handle<promise_type> _Coro_) noexcept : _Coro(_Coro_) {}
};

namespace ranges {
    template <class _Ty, class _Ref, class _Allocator>
    inline constexpr bool enable_view<generator<_Ty, _Ref, _Allocator>> = true;
}

_STD_END

#pragma pop_macro("new")
_STL_RESTORE_CLANG_WARNINGS
#pragma warning(pop)
#pragma pack(pop)

#endif // !_HAS_CXX23 || !defined(__cpp_lib_byte) || !defined(__cpp_impl_coroutine)
#endif // _STL_COMPILER_PREPROCESSOR
#endif // _GENERATOR_
